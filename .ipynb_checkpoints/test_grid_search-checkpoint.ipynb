{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test avec différents paramétres : \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /users/nfs/Etu9/21200169/.local/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.9/site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /users/nfs/Etu9/21200169/.local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /users/nfs/Etu9/21200169/.local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 5.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[K     |████████████████████████████████| 773 kB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 4.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/users/Etu9/21200169/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script nltk is installed in '/users/Etu9/21200169/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2023.12.25 tqdm-4.66.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import common as cmn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.model_selection._validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des données :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fname = \"./datasets/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "alltxts,alllabs = cmn.load_pres(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search (parameters , scoring,preprocessors ,score_to_maximize):\n",
    "    pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(preprocessor=preprocessors)),\n",
    "    ('reg', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    [X_all_train, X_all_test, Y_train, y_test]  = train_test_split(alltxts, alllabs, test_size=0.3, random_state=10, shuffle=True)\n",
    "    \n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, parameters,scoring=scoring, refit=score_to_maximize, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    \n",
    "    grid_search.fit(X_all_train, Y_train)\n",
    "    \n",
    "    \n",
    "    print(\"Meilleurs paramètres trouvés:\")\n",
    "    print(grid_search.best_params_)\n",
    "    #_____________\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_all_test)\n",
    "    \n",
    "    smoothed_pred = gaussian_filter(y_pred,sigma=0.1)\n",
    "    \n",
    "    # Calcul des métriques de performance après le lissage\n",
    "    f1 = f1_score(y_test, smoothed_pred, average='micro')  # or 'macro' or 'weighted'\n",
    "    roc_auc = roc_auc_score(y_test, smoothed_pred)\n",
    "    accuracy = accuracy_score(y_test, (smoothed_pred > 0.5).astype(int))\n",
    "    \n",
    "    print(\"Performance après lissage:\")\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"AUC:\", roc_auc)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #_____________\n",
    "    # print(\"Scores:\")\n",
    "    # print(\"F1 Score:\", grid_search.cv_results_['mean_test_f1_score'])\n",
    "    # print(\"AUC:\", grid_search.cv_results_['mean_test_roc_auc'])\n",
    "    # print(\"Accuracy:\", grid_search.cv_results_['mean_test_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 :\n",
    "On essaye de penaliser notre classe minoritaire avec diffèrentes vaaleurs de pénaisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Meilleurs paramètres trouvés:\n",
      "{'reg__C': 10, 'reg__class_weight': {1: 1, -1: 5}, 'reg__max_iter': 10000, 'reg__penalty': 'l2', 'reg__tol': 0.0001, 'tfidf__binary': True, 'tfidf__max_df': 0.5, 'tfidf__max_features': 100000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Performance après lissage:\n",
      "F1 Score: 0.9050743149094286\n",
      "AUC: 0.7827068919817048\n",
      "Accuracy: 0.8226892707849512\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    1: 1.0,  # Class 1, the majority class, gets weight 1.0 (default weight)\n",
    "    -1: 5.0  # Class -1, the minority class, gets weight 5.0\n",
    "}\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': [ 0.2,0.5],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__ngram_range': [ (1, 2)],\n",
    "    'tfidf__binary': [True],\n",
    "    'tfidf__max_features': [100000],\n",
    "    'reg__class_weight': [{1: 1, -1: w} for w in [1, 5, 10, 20]],  \n",
    "    'reg__max_iter': [10000],\n",
    "    'reg__tol': [1e-4],\n",
    "    'reg__penalty': [ 'l2' ],\n",
    "    'reg__C': [ 1,10,100]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'f1_score': make_scorer(f1_score,pos_label=-1),\n",
    "    'roc_auc': make_scorer(roc_auc_score),\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "preprocessors = lambda x: ((cmn.suppression_chiffres(cmn.majuscules_en_marqueurs((cmn.suppression_balises_html((x)))))))\n",
    "\n",
    "grid_search (parameters , scoring,preprocessors ,'f1_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 :\n",
    "Maximiser le f1 score de la classe minoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Meilleurs paramètres trouvés:\n",
      "{'reg__C': 10, 'reg__class_weight': {1: 1.0, -1: 5.0}, 'reg__max_iter': 10000, 'reg__penalty': 'l2', 'reg__tol': 0.0001, 'tfidf__binary': True, 'tfidf__max_df': 0.5, 'tfidf__max_features': 100000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Performance après lissage:\n",
      "F1 Score: 0.9040320473743795\n",
      "AUC: 0.782878231512926\n",
      "Accuracy: 0.8230427588609248\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    1: 1.0,  # Class 1, the majority class, gets weight 1.0 (default weight)\n",
    "    -1: 5.0  # Class -1, the minority class, gets weight 5.0\n",
    "}\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': [ 0.5],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__ngram_range': [ (1, 2)],\n",
    "    'tfidf__binary': [True],\n",
    "    'tfidf__max_features': [40000,100000],\n",
    "    'reg__class_weight': ['balanced',class_weights],  \n",
    "    'reg__max_iter': [10000],\n",
    "    'reg__tol': [1e-4],\n",
    "    'reg__penalty': [ 'l2' ],\n",
    "    'reg__C': [ 1,10,100]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'f1_score': make_scorer(f1_score,pos_label=-1),\n",
    "    'roc_auc': make_scorer(roc_auc_score),\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "preprocessors = lambda x: (((cmn.majuscules_en_marqueurs((cmn.suppression_balises_html((x)))))))\n",
    "\n",
    "grid_search (parameters , scoring,preprocessors ,'f1_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 :\n",
    "Maximiser roc auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Meilleurs paramètres trouvés:\n",
      "{'reg__C': 1, 'reg__class_weight': 'balanced', 'reg__max_iter': 10000, 'reg__penalty': 'l2', 'reg__tol': 0.0001, 'tfidf__binary': True, 'tfidf__max_df': 0.5, 'tfidf__max_features': 40000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Performance après lissage:\n",
      "F1 Score: 0.8680658364538884\n",
      "AUC: 0.8090931030390787\n",
      "Accuracy: 0.7726203953670644\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    1: 1.0,  # Class 1, the majority class, gets weight 1.0 (default weight)\n",
    "    -1: 5.0  # Class -1, the minority class, gets weight 5.0\n",
    "}\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': [ 0.5],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__ngram_range': [ (1, 2)],\n",
    "    'tfidf__binary': [True],\n",
    "    'tfidf__max_features': [40000,100000],\n",
    "    'reg__class_weight': ['balanced',class_weights],  \n",
    "    'reg__max_iter': [10000],\n",
    "    'reg__tol': [1e-4],\n",
    "    'reg__penalty': [ 'l2' ],\n",
    "    'reg__C': [ 1,10,100]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'f1_score': make_scorer(f1_score,pos_label=-1),\n",
    "    'roc_auc': make_scorer(roc_auc_score),\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "preprocessors = lambda x: (((cmn.majuscules_en_marqueurs((cmn.suppression_balises_html((x)))))))\n",
    "\n",
    "grid_search (parameters , scoring,preprocessors ,'roc_auc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4:\n",
    "essayer de maximiser des deux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Meilleurs paramètres trouvés:\n",
      "{'reg__C': 10, 'reg__class_weight': {1: 1, -1: 5}, 'reg__max_iter': 10000, 'reg__penalty': 'l2', 'reg__tol': 0.0001, 'tfidf__binary': True, 'tfidf__max_df': 0.5, 'tfidf__max_features': 100000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Performance après lissage:\n",
      "F1 Score: 0.9050743149094286\n",
      "AUC: 0.7827068919817048\n",
      "Accuracy: 0.8226892707849512\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    1: 1.0,  # Class 1, the majority class, gets weight 1.0 (default weight)\n",
    "    -1: 5.0  # Class -1, the minority class, gets weight 5.0\n",
    "}\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': [ 0.2,0.5],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__ngram_range': [ (1, 2)],\n",
    "    'tfidf__binary': [True],\n",
    "    'tfidf__max_features': [100000],\n",
    "    'reg__class_weight': [{1: 1, -1: w} for w in [1, 5, 10, 20]],  \n",
    "    'reg__max_iter': [10000],\n",
    "    'reg__tol': [1e-4],\n",
    "    'reg__penalty': [ 'l2' ],\n",
    "    'reg__C': [ 1,10,100]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'f1_score': make_scorer(f1_score,pos_label=-1),\n",
    "    'roc_auc': make_scorer(roc_auc_score),\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "preprocessors = lambda x: ((cmn.suppression_chiffres(cmn.majuscules_en_marqueurs((cmn.suppression_balises_html((x)))))))\n",
    "\n",
    "grid_search (parameters , scoring,preprocessors ,'f1_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
